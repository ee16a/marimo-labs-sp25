{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Lab 3: Multipixel Scanning\n",
    "\n",
    "## EECS 16A: Foundations of Signals, Dynamical Systems, and Information Processing, Spring 2025\n",
    "\n",
    "<!--- \n",
    "    Raghav Gupta raghavgupta@berkeley.edu \n",
    "    Nikhil Ograin ncograin@berkeley.edu\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Instructions](#instructions)\n",
    "* [Lab Policies](#policies)\n",
    "* [Overview](#overview)\n",
    "* [Task 1: Generating Multipixel Scanning Matrices](#matrixGenIntro)\n",
    "    * [Task 1a: Imaging Mask Matrix Practice](#simpleMatrixGen)\n",
    "    * [Task 1b: Generating a Random Binary Mask Matrix](#randomBinaryMatrixGen)\n",
    "* [Task 2: Imaging Simulator](#simulatorIntro)\n",
    "    * [Task 2a: Constructing an Ideal Sensor Model](#idealSensor)\n",
    "        * [Image Reconstruction Using the Ideal Sensor Model + Matrix Inverse](#idealReconstruction)\n",
    "    * [Task 2b: Handling System Non-Idealities](#nonidealities)\n",
    "        * [Noise *(Why So Grainy? ☹)*](#noiseSimulation)\n",
    "    * [Task 2c: Eigenanalysis & the Robustness of Inverse-Based Reconstruction](#eigenanalysis)\n",
    "        * [Graphical Interpretation](#graphicalInterpretation)\n",
    "        * [Revisiting the Identity Matrix](#revisitingIdentity)\n",
    "        * [Comparing Scanning Matrices](#comparingScanning)\n",
    "* [Task 3: Scanning Images](#scanningImages)\n",
    "    * [Task 3a: Single Pixel Sanity Check](#singlePixel)\n",
    "    * [Task 3b: Real Multipixel Imaging](#realImaging)\n",
    "* [Task 4: Understanding Multipixel Use-Cases](#useCases)\n",
    "* [Feedback](#feedback)\n",
    "* [Checkoff](#checkoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='instructions'></a>\n",
    "## Instructions\n",
    "\n",
    "* Complete this lab by filling in all of the required sections, marked with `\"YOUR CODE HERE\"` or `\"YOUR COMMENTS HERE\"`.\n",
    "* When you finish, submit a checkoff request to get checked off (i.e. earn credit) for this lab. Be ready to answer a few questions to show your understanding of **each section**.\n",
    "* Labs will be graded based on completion for **teams of 2 students**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='policies'></a>\n",
    "## Lab Policies\n",
    "* **YOU MUST ATTEND THE LAB SECTION YOU ARE ENROLLED IN. If you anticipate missing a section, please notify your GSI in advance.**\n",
    "* **You are required to return all parts checked out at the beginning of the lab section unless told otherwise.**\n",
    "* **You are free to stay for the full allotted time and hack around with the lab equipment, but please reserve the GSI's time for lab-related questions.**\n",
    "* **Food and drinks are not allowed in the lab.** \n",
    "* **Clean up, turn off all equipment, and log off of computers before leaving.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview'></a>\n",
    "# <span style='color:blue'>Overview</span>\n",
    "\n",
    "Recall that in the last lab, you illuminated the object pixel-by-pixel. This week, you'll flex your linear algebra skills and try something different. You will experiment with imaging methods that illuminate *multiple pixels* at a time. You'll find that if we design our masks in a clever way, our imaging system can be much more robust to noise than the single-pixel approach. You will generate a binary mask matrix that the projector will use to illuminate multi-pixel patterns onto your object. Before scanning your custom images, you'll walk through a basic multi-pixel imaging simulation to understand how it works, delve deeper into the differences between ideal and non-ideal imaging, and understand why certain matrices are better than others at imaging in noisy systems.\n",
    "\n",
    "*Note: A lot of the code to complete this lab will be provided for you to run. However, looking over the code to try to understand what it does is **highly encouraged**. Additionally, we will be writing **functions** to enable multiple parts of this lab to reuse the same code with minimal copy + pasting.*\n",
    "\n",
    "**<span style = \"color: red\">Run the following code block to get access to several pre-written functions and helper libraries.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run scripts/helpers.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = 'matrixGenIntro'><span style = \"color: blue\">Task 1: Generating Multipixel Scanning Matrices</span></a>\n",
    "\n",
    "**Note: This lab will use 0-indexing, as Python uses 0-indexing.**\n",
    "\n",
    "Recall that we can define our imaging system by the following mathematical model:\n",
    "\n",
    "$$ H \\vec{i} = \\vec{s} $$ \n",
    "\n",
    "$H$ is the imaging mask matrix, $\\vec{i}$ is our image in column vector form, and $\\vec{s}$ is the sensor output also in column vector form.\n",
    "\n",
    "In Imaging 2, we scanned our image by highlighting one pixel at a time in a mask. Each row $H_k$ of $H$ defined a 1-D representation of each mask. This meant that scanning an image with $n$ pixels would require an $H$ with $n$ rows. Since we project one mask at a time onto our image, we would need to do exactly $n$ scans. Take a $2\\times2$ image for example: $H$ would need exactly 4 rows, and we would make 4 scans.\n",
    "\n",
    "Let's try something different. We'll still do $n$ scans of our image, but let's try to highlight more than one pixel per mask. We still want to be able to reconstruct our image from our sensor values. So the question is: how do you choose which pixels to illuminate with each mask?\n",
    "\n",
    "Begin by assigning each pixel value in the 2x2 image to a variable, $p_{ij}$, where $i$ is the row and $j$ is the column associated with the pixel location. <br/><br/>\n",
    "\n",
    "<center>\n",
    "    <b>2x2 Image</b>\n",
    "<img src=\"images/img_4x4_new.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "<!--\n",
    "In matrix form, the 2x2 image will look like this:\n",
    "$$\\begin{bmatrix} p_{00} & p_{01} \\\\ p_{10} & p_{11} \\end{bmatrix}$$\n",
    "-->\n",
    "\n",
    "In our mathematical model above, we represent the 2x2 image as the 1D column vector: \n",
    "\n",
    "$$\\vec{i} = \\begin{bmatrix} p_{00} \\\\ p_{01} \\\\ p_{10} \\\\ p_{11} \\end{bmatrix}$$\n",
    "\n",
    "Likewise, the sensor reading column vector is represented as:\n",
    "\n",
    "$$\\vec{s} = \\begin{bmatrix} s_0 \\\\ s_1 \\\\ s_2 \\\\ s_3 \\end{bmatrix}$$\n",
    "\n",
    "Where the sensor reading from the $k$th mask is $s_k$. In the example above, the sensor reading from the 2nd mask is $s_2$. (We consider $s_0$ to be the 0th mask.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the relationship between the mask matrix $H$ (with per-row imaging masks $H_k$), the image vector $\\vec{i}$, and the sensor reading vector $\\vec{s}$, we provide you with this **Example System of Linear Equations:**\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "s_0 & = p_{00}\\\\\n",
    "s_1 & = p_{00} + p_{01}\\\\\n",
    "s_2 & = p_{00} + p_{10}\\\\\n",
    "s_3 & = p_{01} + p_{10} + p_{11}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**<span style = \"color: red\">*IMPORTANT*: The above system of equations is only an example! It only serves an illustrative purpose for this section of the lab. Please do not use it for the rest of the lab.</span>**\n",
    "\n",
    "How would you represent the above as a mask matrix $H$? Convince yourself that the image below does just that (where a **white pixel** represents a value of **1** and a **black pixel** represents a value of **0**).</font><br/><br/>\n",
    "\n",
    "<center>\n",
    "    <b>Imaging Mask Matrix $H$ for the Example System of Linear Equations</b>\n",
    "<img src=\"images/mask_sample_4x4.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Recall that each row of our mask matrix represents a mask in 1-D form. We must *reshape* each row $H_k$ of $H$ into the 2-D mask (Mask $k$) itself before projecting it onto the image. To make sense of the $H$ matrix, it is helpful to look at each mask individually. Let's consider $H_0$, the 0th row of $H$. When we reshape the 1-D $1\\times4$ row into a $2\\times2$ mask, we get Mask 0 (below on the left). <br/><br/>\n",
    "\n",
    "<center>\n",
    "    <b>Individual Masks for the Example System of Linear Equations</b>\n",
    "<img src=\"images/H_4x4_split.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Now we can see that \n",
    "\n",
    "$$H_k \\vec{i} = s_k$$ \n",
    "\n",
    "represents one of the equations in our system. \n",
    "\n",
    "For example, the equation for $s_0$ only depends on one pixel, $p_{00}$, i.e. the top-left pixel of our $2\\times2$ image. We can represent it algebraically as:\n",
    "    \n",
    "$$s_0 = H_0 \\vec{i}$$\n",
    "\n",
    "where $H_0 = \\begin{bmatrix} 1 & 0 & 0 & 0 \\end{bmatrix}$.\n",
    "\n",
    "So numerically, we can represent the equation as:\n",
    "\n",
    "$$s_0 = \\begin{bmatrix} 1 & 0 & 0 & 0 \\end{bmatrix} \\begin{bmatrix} p_{00} \\\\ p_{01} \\\\ p_{10} \\\\ p_{11} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'simpleMatrixGen'><span style = \"color: blue\">Task 1a: Imaging Mask Matrix Practice</span></a>\n",
    "\n",
    "Now that we have an understanding of how to approach multipixel scanning, let's test our approach on a new system of equations:\n",
    "\n",
    "<center>\n",
    "<b>Lab 3 System of Equations</b>\n",
    "$$\n",
    "\\begin{align}\n",
    "s_0 & = p_{00} + p_{01} + p_{10}\\\\\n",
    "s_1 & = p_{00} + p_{11}\\\\\n",
    "s_2 & = p_{01} + p_{11}\\\\\n",
    "s_3 & = p_{10} + p_{11}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**<span style=\"color: red\">For a 2x2 image represented by $\\vec{i}$, create the matrix `H` such that $ H \\vec{i} = \\vec{s} $ represents the `Lab 3 System of Equations` above.</span>**\n",
    "    \n",
    "*Hint: Look up how to use the `np.array` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create H (4x4) for the Lab 3 System of Equations --------------------\n",
    "H_new = # YOUR CODE HERE\n",
    "\n",
    "# Show H\n",
    "plt.imshow(H_new, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title(\"4x4 H\")\n",
    "\n",
    "# Run autograder\n",
    "test_H_new(H_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we will *reshape* rows $H_k$ of the mask matrix, $H$, into the individual masks themselves. \n",
    "\n",
    "**<span style=\"color: red\">You will help write a function `show_masks` that enables you to iterate through the 4 individual masks and display them as 2x2 images (1 TODO). Double check that the generated masks make sense visually and have the expected number of illuminated pixels. The `show_masks` function will be reused later.</span>**\n",
    "\n",
    "*Hint: Reference your code from the part of Imaging 2 where you checked to make sure that the scanning matrix was producing the correct pattern by displaying each of the individual masks. You might want to check out the command `np.reshape`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "#  `H`: Mask matrix\n",
    "#  `rows`: Number of rows in image (height)\n",
    "#  `cols`: Number of columns in image (width)\n",
    "#  `num_masks_shown`: Number of individual masks to display (starting from `H` row 0)\n",
    "def show_masks(H, rows, cols, num_masks_shown):\n",
    "    plt.figure(figsize = (18, 12)) \n",
    "    # Use this for loop to iterate through the first `numMasksShown` rows of `H` \n",
    "    # you want to display.\n",
    "    for k in range(num_masks_shown):\n",
    "        plt.subplot(num_masks_shown, num_masks_shown, k + 1)\n",
    "    \n",
    "        # TODO: Reshape the `k`th row of `H` to be shown in 2D --------------------\n",
    "        mask = # YOUR CODE HERE\n",
    "  \n",
    "        plt.imshow(mask, cmap = \"gray\", interpolation = \"nearest\")\n",
    "        # Title also prints number of illuminated (white) pixels per mask\n",
    "        plt.title(\"Mask \" + str(k) + \": \" + str(np.sum(H[k])) + \" Illuminated Pixels\")\n",
    "    plt.show()\n",
    "\n",
    "# Show individual masks    \n",
    "show_masks(H = H_new, rows = 2, cols = 2, num_masks_shown = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'randomBinaryMatrixGen'><span style = \"color: blue\">Task 1b: Generating a Random Binary Mask Matrix</span></a>\n",
    "\n",
    "A 2x2 image is not very interesting to scan, so we will instead try to scan a 32x32 region. Note that this image has different dimensions compared to last week's image!\n",
    "\n",
    "**<span style=\"color: red\">To scan a 32x32 image, what dimensions must our scanning matrix $H$ have? What does the number of rows of $H$ correspond to? What does the number of columns correspond to? What do the elements in each column of $H$ represent?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'd like to use a sufficiently interesting set of masks and you *really* don't want to be constructing such a large matrix by hand, we will provide you with a function that generates a random binary mask matrix $H$ for you, given dimensions `(rows, cols)` corresponding to your image's height/width, and, as we'll go into later, a parameter for the average number of illuminated pixels per scan. The resulting matrix $H$ will consist entirely of 0's and 1's, where 1's are randomly interspersed among 0's, and each row will contain approximately **`avg_1s_per_row`** (see function arguments) # of 1's. Not all rows will contain the same number of 1's!\n",
    "\n",
    "**<span style=\"color: red\">Run the `generate_random_binary_mask` function and visually inspect that the generated `randomH` (with approximately 300 pixels illuminated per scan) has the right dimensions & visually looks random. Don't worry too much about how this function is actually implemented, but you can check out the code in `scripts/helpers.py`.</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the randomH mask\n",
    "randomH = generate_random_binary_mask(avg_1s_per_row = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">Use the `show_masks` function created earlier to show the first 4 individual masks (rows 0 to 3 of `randomH`) as 32x32 images.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reuse the `show_masks` function from earlier to display the first 4 masks of randomH. -------\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to the representation of the imaging system as taking a matrix-vector product. Recall that in the Imaging 2 lab, you reconstructed the image column vector $\\vec{i}$ from the sensor reading vector $\\vec{s}$ by applying the equation:\n",
    "\n",
    "$$\\vec{i} = H^{-1} \\vec{s}$$\n",
    "\n",
    "You used the **identity** matrix for $H$, for which the inverse $H^{-1}$ exists. In order to apply the same reconstruction method assuming a randomly generated binary $H$, you first need to make sure that your $H$ is actually invertible. \n",
    "\n",
    "**<span style=\"color: red\">What must be true about the rows of $H$ for it to be invertible? What about the columns?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on invertibility**\n",
    "\n",
    "Luckily, randomly generated binary matrices are *usually* invertible. However, the function we provided still double checks that the generated $H$ is indeed invertible (using an alternative method to Gaussian elimination), and re-generates the matrix if it's not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = 'simulatorIntro'><span style = \"color: blue\">Task 2: Imaging Simulator</span></a>\n",
    "\n",
    "Let's pause for a minute before we start capturing images with the projector. Recall from Imaging 2 that the projector setup is usually placed inside a cardboard box to prevent light from the outside world disturbing our sensor. Even when the projector is turned off, there might be a significant amount of light inside the box. The sensor and related circuits generate noise in our measurements due to thermal physics and other environmental factors. The refresh rate of the projector also contributes to noise. Thus, non-idealities like noise will inevitably be present in our setup. This is a limitation of the real-world setup that greatly affects our ability to reconstruct the image using the light sensor data. That's why it's important to build a simulator that **accurately models** what happens when we try to capture an image, including non-idealities that we can potentially compensate for.\n",
    "\n",
    "Our virtual simulated projector will artificially generate noise to affect sensor results in a way that mirrors this real-world phenomenon.\n",
    "\n",
    "## <a id = 'idealSensor'><span style = \"color: blue\">Task 2a: Constructing an Ideal Sensor Model</span></a>\n",
    "\n",
    "Let's first construct a function that emulates what we would *hope* occurs when we scan an image (ideal imaging). An image (represented as the column vector $\\vec{i}$) is placed in a region that can be illuminated by the projector. The projector projects a sequence of masks $H_k$ onto the image (illuminating certain pixels at a time). In our simulation, the digitized 'light sensor' output is the sum of the brightnesses detected across illuminated pixels. The $k^{th}$ entry of the sensor output vector, $s_k$, corresponds to the $k^{th}$ scan.\n",
    "\n",
    "Recall that these operations can be represented by the previously defined mathematical model:\n",
    "\n",
    "$$\\vec{s} = H \\vec{i}$$ \n",
    "\n",
    "**<span style=\"color:red\"> Your first goal is to translate this ideal model into a `simulate_ideal_capture` function (Fill in the TODO). Apply the function using the supplied 32x32 image of a playing card and your generated random binary matrix `H`. Display the simulated sensor reading as a 32x32 image.</span>**\n",
    "\n",
    "*Hint: Remember to use `np.dot` to do matrix multiplication.*\n",
    "\n",
    "The playing card you're trying to image should look like: <br/><br/>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/raw_card.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Think about what the output sensor readings will look like. Given randomly generated masks, would you expect the output sensor readings to be remotely recognizable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: \n",
    "#  `i2D`: 2D image you're trying to capture\n",
    "#  `H`: Mask matrix\n",
    "#  `matrixName`: Name of mask matrix (for image title)\n",
    "#  `display`: Whether to display the sensor output as a 2D image\n",
    "# Outputs:\n",
    "#  `s`: Sensor reading column vector\n",
    "def simulate_ideal_capture(i2D, H, matrix_name, display = True):\n",
    "    # Number of pixels in your image = `iHeight` * `iWidth`\n",
    "    i_height = i2D.shape[0]\n",
    "    i_width = i2D.shape[1]\n",
    "    i_size = i_height * i_width\n",
    "    \n",
    "    # TODO: Convert the 2D image `i2D` into a 1D column vector `i`\n",
    "    i = # YOUR CODE HERE\n",
    "    \n",
    "    # TODO: Perform the matrix operation to emulate the ideal imaging system  --------------\n",
    "    s = # YOUR CODE HERE\n",
    "    \n",
    "    if display:\n",
    "        # Reshape the simulated sensor output `s` into an appropriately \n",
    "        # sized 2D matrix `s2D` and plots it\n",
    "        s2D = np.reshape(s, (i_height, i_width))\n",
    "        plt.imshow(s2D, cmap = \"gray\", interpolation = \"nearest\")\n",
    "        plt.title(\"Ideal Sensor Output, Using %s\" % matrix_name)\n",
    "        plt.show()\n",
    "    return s\n",
    "\n",
    "# Load playing card image + display it\n",
    "i2D = np.load(\"scripts/raw_card.npy\")\n",
    "plt.imshow(i2D, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title(\"Raw 32x32 Image of the playing card\")\n",
    "plt.show()\n",
    "\n",
    "# Simulate the image capture step (ideal)\n",
    "s = simulate_ideal_capture(i2D = i2D, H = randomH, matrix_name = \"Random H\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'idealReconstruction'><span style = \"color: blue\">Image Reconstruction Using the Ideal Sensor Model + Matrix Inverse</span></a>\n",
    "\n",
    "As you can see, for *multipixel imaging*, the sensor output does not resemble the original image in any way. By applying the randomly generated mask matrix $H$, you've essentially encrypted the image data, making it unrecognizable to anyone who doesn't know the exact mask matrix $H$ you used (otherwise known as the encryption key).\n",
    "\n",
    "If you know the key $H$, as stated before, you can reconstruct/decrypt the desired image column vector $\\vec{i}$ from the sensor reading vector $\\vec{s}$ by essentially *undoing* what the imaging system did to the image and applying the equation:\n",
    "\n",
    "$$\\vec{i} = H^{-1} \\vec{s}$$\n",
    "\n",
    "Again, it's important that we've selected an invertible $H$. \n",
    "\n",
    "**<span style=\"color:red\">Now your job is to help write a function `ideal_reconstruction` (Fill in the TODO) that accepts the column vector $\\vec{s}$ and mask matrix $H$ and displays the reconstructed estimate of $\\vec{i}$ as a 2D image. Run the reconstruction function using the previously computed `s` and mask matrix `H` and verify that it worked as you expected.</span>**\n",
    "\n",
    "*Hint: Use `np.linalg.inv` to invert a matrix.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "#  `H`: Mask matrix\n",
    "#  `matrix_name`: Name of mask matrix (for image title)\n",
    "#  `s`: Sensor reading column vector\n",
    "#  `rows`: Number of rows in image (height)\n",
    "#  `cols`: Number of columns in image (width)\n",
    "def ideal_reconstruction(H, matrix_name, s, rows = 32, cols = 32, real_imaging = False):\n",
    "    \n",
    "    # TODO: Perform the matrix operations required for reconstruction --------------------\n",
    "    i = # YOUR CODE HERE\n",
    "    \n",
    "    if real_imaging:\n",
    "        i = noise_massage(i, H)\n",
    "    \n",
    "    # Reshape the column vector `i` to display it as a 2D image\n",
    "    i2D = # YOUR CODE HERE  \n",
    "\n",
    "    # We're going to exclude the top row and left-most column from display\n",
    "    plt.imshow(i2D[1:, 1:], cmap = \"gray\", interpolation = \"nearest\")\n",
    "    plt.title(\"Reconstructed Image, Using %s\" % matrix_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run ideal reconstruction    \n",
    "ideal_reconstruction(H = randomH, matrix_name = \"Random H\", s = s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'nonidealities'><span style = \"color: blue\">Task 2b: Handling System Non-Idealities</span></a>\n",
    "\n",
    "The ideal reconstruction demonstrated above works great, right? Unfortunately, due to real-world non-idealities alluded to earlier, if you directly tried to image a drawing with the multipixel masks in $H$, the reconstruction would probably look terrible. A significant amount of engineering effort is focused on how to best translate theory into practice by attempting to compensate for or remove non-idealities. In the following sections, we'll look at some of the worst offenders and what we can do to improve reconstruction quality. \n",
    "\n",
    "### <a id = 'noiseSimulation'><span style = \"color: blue\">Noise *(Why So Grainy? ☹)*</span></a>\n",
    "\n",
    "We will see noise again later in Module 3,-- if you're really interested in modelling noise and its effects, it's covered more extensively upper division classes including EE123, EE126, EE142 -- but for now it's important to realize that both the light sensor circuit and the projector add noise that shows up in the digitized sensor output. Noise is what causes photos to look grainy or fuzzy. As an example, if your single pixel imaging system from last week happened to be very noisy (and usually, the cheaper the system, the noisier it is...), imaging the playing card from before might've produced something like: <br/><br/>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/noisy_card.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "The noisier your system, the less the resultant image will look like what you expected ☹.\n",
    "\n",
    "One way to make noise less problematic is to increase the number of pixels illuminated per scan. This increases the \"signal level\" (i.e. contributions from things we actually care about). At the same time, the amount of noise coming from the light sensor circuit and projector should stay mostly constant, thus improving the so-called *signal-to-noise ratio* (SNR) of our system. This is important to know when choosing `avg_1s_per_row` for our random binary mask.\n",
    "\n",
    "However, in reality, the number of pixels illuminated per scan is limited by the ambient light sensor circuit. This is because at high brightness levels, the sensor circuit becomes saturated. The difference in sensor reading for each additional illuminated pixel becomes quite small, and thus we lost the ability to differentiate the number of illuminated pixels.\n",
    "\n",
    "Another way to make noise less problematic is to repeat each scan $k$ (with the same illumination pattern) many times and *average* the sensor outputs. The desired signal is always present, but the *random* error (noise) changes on each repeat scan. Thus, you can \"average out the noise\" at the expense of spending more time acquiring the image. This is actually what the Arduino code used in lab does under the hood.\n",
    "\n",
    "Generally speaking, we would like to build a sensing system that is as noise robust as possible, but what does that entail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'eigenanalysis'><span style = \"color: blue\">Task 2c: Eigenanalysis &amp; the Robustness of Inverse-Based Reconstruction</span></a>\n",
    "\n",
    "## <span style = \"color: red\">THIS SECTION IS VERY IMPORTANT. PLEASE READ CAREFULLY.</span>\n",
    "When noise is included, the mathematical model of our imaging system would look like:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} + \\vec{\\omega} +\\vec{o} $$\n",
    "\n",
    "The vector $\\vec{o}$ is a vector of equal entries, which represents a constant offset from extra light from the projector while it is projecting the color black. Even though black is supposed to be an absence of light, there is still a glow present from the projector that can offset our measurement by a scalar amount. This needs to be removed, but can easily be done so by measuring and subtracting it. \n",
    "\n",
    "The elements ($\\omega_k$) of the column vector $\\vec{\\omega}$ correspond to the random amounts of noise added at each measurement $s_k$. We cannot remove noise, but we can try to reduce its effects.\n",
    "\n",
    "For example, you might expect your sensor readings $\\vec{s}$ to be something like \n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{s_{expected}} = \\begin{bmatrix}\n",
    "51 \\\\\n",
    "65 \\\\\n",
    "42 \\\\\n",
    "\\vdots \\\\\n",
    "32\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "But you may get something like\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{s_{reality}} = \\begin{bmatrix}\n",
    "61.2 \\\\\n",
    "76.0 \\\\\n",
    "51.7 \\\\\n",
    "\\vdots \\\\\n",
    "44.0\n",
    "\\end{bmatrix}\\;.\n",
    "\\end{equation}\n",
    "\n",
    "This means that what you are getting is really\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{s_{reality}} = \\vec{s_{expected}} \\;+\\; \\vec{\\omega} \\;+\\; \\vec{o}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "        61.2 \\\\\n",
    "        76.0 \\\\\n",
    "        51.7 \\\\\n",
    "        \\vdots \\\\\n",
    "        44.0\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        51 \\\\\n",
    "        65 \\\\\n",
    "        42 \\\\\n",
    "        \\vdots \\\\\n",
    "        32\n",
    "    \\end{bmatrix}\n",
    "    \\;+\\;\n",
    "    \\begin{bmatrix}\n",
    "        0.2 \\\\\n",
    "        1.0 \\\\\n",
    "        -0.3 \\\\\n",
    "        \\vdots \\\\\n",
    "        2.0\n",
    "        \\end{bmatrix}\n",
    "    \\;+\\;\n",
    "    \\begin{bmatrix}\n",
    "        10 \\\\\n",
    "        10 \\\\\n",
    "        10 \\\\\n",
    "        \\vdots \\\\\n",
    "        10\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where the last two vectors are $\\vec{\\omega}$ and $\\vec{o}$\n",
    "\n",
    "As you can see, once you measure the offset, it is very easy to just subtract from your measurements. We will take care of this for you in the experimental portion of the lab (below), so you don't need to worry about it. We will ignore it in the rest of the notebook, and assume it is subtracted.\n",
    "\n",
    "From this point forward, our key equation will look like this:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} + \\vec{\\omega}$$\n",
    "\n",
    "Now we will try to reconstruct the image $\\vec{i}$ with matrix inversion $H^{-1}$:\n",
    "\n",
    "$$ H^{-1}\\vec{s} = H^{-1}H \\vec{i} + H^{-1}\\vec{\\omega}$$\n",
    "\n",
    "$$ H^{-1}\\vec{s} = \\vec{i} + H^{-1}\\vec{\\omega}$$\n",
    "\n",
    "We will call $H^{-1}\\vec{s} = \\vec{i_{est}}$ leaving us with \n",
    "$$ \\vec{i_{est}} = H^{-1} \\vec{s} = \\vec{i} + H^{-1} \\vec{\\omega} $$\n",
    "\n",
    "Remember that we were hoping to solve for just $\\vec{i}$. The additional undesired term $H^{-1} \\vec{\\omega}$ is what we call our reconstruction *error*, which results from linearly transforming the original noise vector $\\vec{\\omega}$ by $H^{-1}$. This implies that our choice of $H$ (and therefore $H^{-1}$) strongly influences how robust our overall imaging system is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build some intuition on why this is the case, recall that matrix-vector multiplication $A \\vec{x} = \\vec{b}$ linearly transforms $\\vec{x}$ into $\\vec{b}$ via scaling and rotation, as designated by $A$. Additionally, recall that the eigenvalues $\\lambda_i$ and $N$ length eigenvectors $\\vec{v_{\\lambda_i}}$ of an $N \\times N$ matrix $A$ can be found by solving for:\n",
    "\n",
    "$$A \\vec{v_{\\lambda_i}} = \\lambda_i \\vec{v_{\\lambda_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying both sides of this equation by $A^{-1}$ and dividing by $\\lambda_i$ allows us to rewrite this equation as:\n",
    "\n",
    "$$A^{-1} \\vec{v_{\\lambda_i}} = \\frac{1}{\\lambda_i} \\vec{v_{\\lambda_i}} $$ \n",
    "\n",
    "How does this help reconstruct our image? We know that $H$, which is an $N \\times N$ matrix, is invertible, and thus we know it has at most $N$ linearly independent eigenvectors. \n",
    "\n",
    "Our matrix $H$ also has another property, which we haven't learned about yet: it is **diagonalizable**. Diagonalizable matrices are beyond the scope of this course (but covered in EECS16B). For now, all you need to know is that a diagonalizable $N \\times N$ matrix $H$ has *precisely* N linearly-independent eigenvectors.\n",
    "    \n",
    "So if we know $H$ has N eigenvectors, we know they span $\\mathbb{R}^N$. In other words, the eigenvectors of $H$ form a basis for $\\mathbb{R}^N$. Well, guess what? Our noise vector lies in $\\mathbb{R}^N$. So we can write it as a linear combination of the eigenvectors like so:\n",
    "\n",
    "$$\\vec{\\omega} = \\alpha_1 \\vec{v_1} + ... + \\alpha_N \\vec{v_N}$$\n",
    "\n",
    "Now if we apply $H^{-1}$ to both sides of the equation,\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = H^{-1} \\alpha_1 \\vec{v_1} + ... + H^{-1}\\alpha_N \\vec{v_N}$$\n",
    "\n",
    "Pull out the $\\alpha$ constants in front of $H^{-1}$ since scalars commute with matrices\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = \\alpha_1 H^{-1} \\vec{v_1} + ... + \\alpha_N H^{-1} \\vec{v_N}$$\n",
    "\n",
    "And we can apply the eigenvector identity shown above:\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = \\alpha_1 \\frac{1}{\\lambda_1} \\vec{v_1} + ... + \\alpha_N \\frac{1}{\\lambda_N} \\vec{v_N}$$\n",
    "\n",
    "So we can see that regardless of the scaling constants $\\alpha$, if we have very large eigenvalues of $H$ then each component of $\\vec{\\omega}$ is attenuated, and likewise if each eigenvalue is small, the noise vector will be amplified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'graphicalInterpretation'><span style = \"color: blue\">Graphical Interpretation</span></a>\n",
    "\n",
    "Another way we can picture this is by showing a graphical example, thinking of how $H$ is a transformation that rotates and scales vectors. In the following image, we have our ideal sensor readings, $H\\vec{i}$ and a noise vector, $\\vec{\\omega}$. After applying two different matrices, $H_1^{-1}$ and $H_2^{-1},$ we can see how each vector is transformed. Ideally we would want the $\\vec{\\omega}$ vector to be $\\vec{0}$, so the recovered image is the same as the ideal reconstruction. Adding everything together to get the final result, we have $\\vec{i}+H^{-1}\\vec{\\omega}$. Depending on the choice of $H$, the noise may end up amplified or attenuated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/2d_transform.jpg\" align=\"center\"/>\n",
    "    <b>Visual representation of the effect of different matrices on the noise vector $\\omega$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically, we can also see what happens to the noise with different matrices by applying them to a given noise vector. We will now introduce a special matrix called the <a href=\"https://mathworld.wolfram.com/HadamardMatrix.html\" target=\"_blank\">Hadamard matrix</a>. It has interesting properties useful in many applications. **The code below prints out the magnitude (norm) of the noise vectors after applying the inverses of the random masking matrix and the Hadamard matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the random binary matrix\n",
    "randomH = generate_random_binary_mask(avg_1s_per_row = 300, plot=False)\n",
    "# Recall from the beginning of the lab that the H matrix refers to the randomH matrix.\n",
    "\n",
    "# Creates the hadamardH matrix with interesting, useful properties\n",
    "hadamardH = create_hadamard_matrix(shape = randomH.shape, plot=False)\n",
    "\n",
    "# Noise vector of mean 0, with standard deviation `sigma`\n",
    "sigma = 7\n",
    "noise = np.random.normal(0, sigma, randomH.shape[0])\n",
    "\n",
    "# Apply hadamardH inverse to the noise vector, and then compute its norm\n",
    "hadamard_norm = np.linalg.norm(np.dot(np.linalg.inv(hadamardH), noise))\n",
    "\n",
    "# Apply randomH inverse to the noise vector, and then compute its norm\n",
    "random_norm = np.linalg.norm(np.dot(np.linalg.inv(randomH), noise))\n",
    "\n",
    "print(\"Norm of the noise vector after hadamardH inverse: \", hadamard_norm)\n",
    "print(\"Norm of the noise vector after randomH inverse: \", random_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which matrix amplifies the noise less?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'revisitingIdentity'><span style = \"color: blue\">Revisiting the Identity Matrix</span></a>\n",
    "We know that the identity matrix is invertible, but is it a good masking matrix? To answer that question, we need to know its eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What are the eigenvalues of the Identity matrix? What are its eigenvalues if we scale the identity matrix by a constant? What are its eigenvectors?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the eigenvalues of the identity matrix essentially boils down to \"dimming\" the simulated sensor readings, or making them \"brighter.\" Think about how good your scan would be if the projector only operated on 1%, or conversely 100% of its max light intensity. It is unlikely that both would give you the same quality sensor readings. \n",
    "\n",
    "**Run the next block to show the ideal image, and the noise that gets added to the image. Change the constant that scales the identity from low values like 0.1 to large values like 100 to see how the noise changes with increasing or decreasing eigenvalues.**\n",
    "\n",
    "Note that the noise is visualized in a different color scale than black and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the thing with the image + the noise image = total image.\n",
    "\n",
    "#########################\n",
    "# CHANGE THIS VARIABLE: #\n",
    "scale_factor = 1\n",
    "#########################\n",
    "\n",
    "\n",
    "############# Dont change anything below ###################\n",
    "# Load the image\n",
    "i2D = np.load(\"scripts/raw_card.npy\")\n",
    "M, N = i2D.shape\n",
    "\n",
    "# define the mask matrix\n",
    "H = scale_factor * np.eye(M * N)\n",
    "\n",
    "# Generate a noise vector\n",
    "sigma = 1.25\n",
    "noise = np.random.normal(0, sigma, H.shape[0])\n",
    "noise = np.reshape(noise, (M, N))\n",
    "\n",
    "# assemble noisy measurement\n",
    "s = H.dot(i2D.ravel()).reshape((M, N)) + noise\n",
    "recovered_image = np.linalg.inv(H).dot(s.ravel()).reshape((M, N))\n",
    "\n",
    "# Plot the image, noise, and image with noise\n",
    "plot_image_noise_visualization(i2D, noise, s, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which scaling factor performs better: 0.01 or 1000? Why?</span>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'comparingScanning'><span style = \"color: blue\">Comparing Scanning Matrices</span></a>\n",
    "Now let's take a look at the two matrices we will use to scan, hadamardH and randomH. The block of code below will show the ideal recovered image, along with the noise that gets added on top, and the total result. We will take care of generating the noise--all you have to do is tell us how much noise to add (by setting the `noise_magnitude` variable). In addition to displaying the images, the code will also print out the norm of the modified noise vector $H^{-1}\\vec{\\omega}$ so you can see quantitatively how different matrices impact the noise.\n",
    "\n",
    "[comment]: <> (**<span style=\"color:red\">First, just run the next code block so that you'll have access to `simulateCaptureWithNoise` below.</span>**)\n",
    "**<span style=\"color:red\">You will simulate the imaging system with different amounts of noise added. Run the code block below and change the noise magnitude to see how the output is affected.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Change this #######\n",
    "noise_magnitude = 50.0\n",
    "#########################\n",
    "\n",
    "############# Dont change anything below ###################\n",
    "# Load the image\n",
    "i2D = np.load(\"scripts/raw_card.npy\")\n",
    "M, N = i2D.shape\n",
    "\n",
    "# define the mask matrix\n",
    "randomH = generate_random_binary_mask(avg_1s_per_row = 300, plot=False)\n",
    "hadamardH = create_hadamard_matrix(shape = randomH.shape, plot=False)\n",
    "\n",
    "# Generate a noise vector\n",
    "sigma = noise_magnitude / np.sqrt(M * N) # noise magnitude --> std dev\n",
    "noise = np.random.normal(0, sigma, randomH.shape[0])\n",
    "noise = np.reshape(noise, (M, N))\n",
    "\n",
    "# Plot the image, noise, and image with noise\n",
    "plot_image_noise_visualization(i2D, noise, s, randomH, title=\"Reconstruction with Random $H$\")\n",
    "modified_noise_norm = np.linalg.norm(np.linalg.inv(randomH).dot(noise.ravel()))\n",
    "print(\"Norm of Hinv*w = %0.4f\" % (modified_noise_norm))\n",
    "\n",
    "plot_image_noise_visualization(i2D, noise, s, hadamardH, title=\"Reconstruction with Hadamard $H$\")\n",
    "modified_noise_norm = np.linalg.norm(np.linalg.inv(hadamardH).dot(noise.ravel()))\n",
    "print(\"Norm of Hinv*w = %0.4f\" % (modified_noise_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What noise magnitudes did you have to use for each of the two matrices to make the image borderline unrecognizable?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next section, we will examine the Hadamard matrix in a bit more detail. We will use the function `eigen_analysis_comparison` that plots a histogram of the magnitudes of the eigenvalues of your $H$'s and their respective inverses (x axis = magnitude bins, y axis = number of eigenvalues within the bin's magnitude range). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run scripts/helpers.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigenvalues of both randomH and hadamardH\n",
    "eigen_analysis_comparison(H1 = randomH, matrix_name_1 = \"Random Binary H\",\\\n",
    "                          H2 = hadamardH, matrix_name_2 = \"Hadamard H\")\n",
    "\n",
    "randomH_inv = np.linalg.inv(randomH)\n",
    "hadamardH_inv = np.linalg.inv(hadamardH)\n",
    "\n",
    "# Plot the eigenvalues of both the inverse of randomH and the inverse of hadamardH\n",
    "eigen_analysis_comparison(H1 = randomH_inv, matrix_name_1 = \"Inverse of Random Binary H\",\\\n",
    "                          H2 = hadamardH_inv, matrix_name_2 = \"Inverse of Hadamard H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which of the two matrices `randomH` and `hadamardH` do you think is more noise robust and would result in a better reconstruction? Justify your answer using the eigenvalue histograms above.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scanningImages'></a>\n",
    "# <span style=\"color:blue\">Task 3: Scanning Images</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id ='setup'></a><span style = \"color: blue\">Hardware Setup</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to transfer this theoretical masking procedure to a real-life imaging setup, you will build some hardware. This is the same hardware you built for Imaging 2 (last week's lab), but some pieces may have shifted around. Please go through this section **carefully** to validate your setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id ='setup'></a><span style = \"color: blue\">Box Setup</span>\n",
    "<img src=\"images/projector_setup.jpg\" style=\"width:500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take the cardboard box at your station down from the top left next to some of the lab equipment, and open the top. **Only remove cables and loose items as needed**. The projector setup shown above should be **left inside the box**.\n",
    "2. Tape the index card you drew on inside the box so that the projector can project onto it (see image).\n",
    "3. Place the breadboard such that the side with the holes on it is facing the index card. The Arduino should then rest on the bottom of the box behind the imaging circuit and underneath the projector. Make sure the light sensor is centered at the top, as in the picture above. Try your best to ensure that the wires do not obstruct the projection from the projector onto the index card.\n",
    "4. Orient the projector so the lens is facing towards the object being imaged, and the ports are facing the opposite direction (see image).\n",
    "5. **Pay close attention to where the holes are in the box, picture on next page**. The holes are cut out to make connecting the mini-HDMI and power cables easier. Align the holes to both the circular power connector and the mini-HDMI port on the back of the projector to the short, back side of the box that has a hole in it.\n",
    "6. Route the power cable through the back to the DC connector and the mini-HDMI cable (at your lab station behind the keyboard under the monitor stand, **one end already connected to your lab computer**) through the back and connect them both to the projector **very gently**. Please ensure you’re using the right projector ports.\n",
    "    <img src=\"images/projector_overview_ports.png\" style=\"width:400px\"/>\n",
    "7. Take the long USB cable and route it through the side hole (or back) and connect it to the Arduino.\n",
    "8. The power cable must be plugged into an outlet - there are outlets at each station (see picture). Make sure the barrel connector is fully plugged into your projector - if the connection is loose during the scan you may have issues. A red light should show on the back of the projector to indicate that it is charging. Turn on the projector by pressing and holding the power button on the back.\n",
    "9. Plug the USB 2.0 end of the USB cable into the lab computer.\n",
    "10. Confirm your setup with the full setup below\n",
    "\n",
    "<center style=\"font-size: 18px; font-weight: bold;\">\n",
    "<div style=\"display: inline-block; margin-left: auto; margin-right: auto;\" border=\"0\"><img style=\"height: 300px;\" src=\"images/box_setup.jpg\"/></div>\n",
    "<div style=\"display: inline-block; margin-left: 100px; margin-right: auto;\" border=\"0\"><img style=\"height: 300px;\" src=\"images/box_setup_side.jpg\"/></div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id ='setup'></a><span style = \"color: blue\">Projector Setup</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/projector_overview.png\" style=\"width:500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup the projector with the following steps:**\n",
    "1. Turn on the projector by holding down the Power button (see the previous figure). You should see a green light turn on when it powers on.\n",
    "2. Find the Focus Adjustment wheel on the side of the projector to adjust the focus of the projection onto the box. Focus it as close as possible.\n",
    "<img src=\"images/projector_home.jpg\" style=\"width:400px\"/>\n",
    "3. Using the left/right arrows on the Directional Pads, select **INPUTS** on the projector's main menu, then **DIGITAL**. After a few seconds, you should see the Windows 10 desktop.\n",
    "<img src=\"images/projector_inputs.jpg\" style=\"width:400px\"/>\n",
    "4. If you see the Windows 10 taskbar at the bottom of the projected screen, take the following precautions:\n",
    "    - Hit the Windows key and type Settings.\n",
    "    - Click on the Personalization icon.\n",
    "    - Click on Taskbar on the left side.\n",
    "    - Under the Multiple Displays section, turn Show taskbar on all displays off.\n",
    "5. If your monitor turns off, hit Windows key and P at the same time. Then select “Extend”\n",
    "6. Use the **Back button** on the projector to return to displaying the **main menu**.\n",
    "7. Use the left/right arrows to select the **Settings** option (gears icon, see picture on previous page).\n",
    "<img src=\"images/projector_settings.jpg\" style=\"width:400px\"/>\n",
    "8. Select **Picture Mode** and change the **Picture Mode** from Standard to **User**.\n",
    "9. **IMPORTANT**: Use the down arrow to move the cursor down to Contrast. Then use the right arrow to adjust the contrast to **100**.\n",
    "10. **IMPORTANT**: Move the cursor down to Brightness and use the left arrow to adjust the brightness to **0**.\n",
    "11. To **Confirm the selection**, hit **OK** and exit the menu with the **Back button**.\n",
    "12. Go back to **Settings** and select **ECO** for **brightness**\n",
    "13. Hit the button **SOURCE** and then **DIGITAL** and make sure that you see the Windows 10 desktop on your projector.\n",
    "14. Place the properly set up projector inside the box, as shown in the image above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id ='setup'></a><span style = \"color: blue\">Arduino Leonardo Setup</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Launch **Arduino IDE** (from Desktop)\n",
    "2. Open the **AnalogReadSerial.ino** file in Arduino IDE (*File > Open*). This will be located in the lab files you downloaded.\n",
    "3. Select *Tools > Board > Arduino Leonardo*.\n",
    "4. Verify the correct Serial Port is selected in the Ardunio IDE by going to *Tools > Port*. If the selected value already displays the board name after the COM port (i.e. \"COM5 (Arduino Leonardo)\"), proceed to the next step. If not, open the Windows \"Device Manager\" and look for the Arduino Leonardo's COM Port under \"COM Ports\", then select this port in the Arduino IDE.\n",
    "5. Upload the code by clicking on the Upload button (white circle with a right-pointing arrow, as shown below):\n",
    "<img src=\"images/arduino_menu.png\" style=\"width:200px\"/>\n",
    "6. Hit the **RESET** button on your Arduino (labeled reset or RST).\n",
    "7. To verify that the program is working, **type a 6 into the serial monitor** (*Tools > Serial Monitor*). **You will need to set the Baud Rate to 115200**. You should see a reading from the ambient light sensor appear. If the numbers increase with light and decrease with less light your setup is good. You must close this window before continuing.\n",
    "<img src=\"images/arduino_serial_monitor.png\" style=\"width:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Double check that you've done the following before proceeding:</span>**\n",
    "\n",
    "* Upload `AnalogReadSerial` to the Arduino. Press the reset button on the Arduino to make sure the script is running.\n",
    "\n",
    "* **Close out of the Arduino IDE Serial Monitor.** Not doing so will result in your COM port being unavailable.\n",
    "\n",
    "* Make sure the projector is connected and projecting the correct image. It should show a smaller version of your desktop (windows logo by default).\n",
    "\n",
    "* Seal the imaging system inside the box to keep ambient light out during scanning. If the holes for cables are too big, try to have them face a solid, unmoving object that can block out light. Alternatively, cover the entire the box with clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='singlePixel'></a>\n",
    "### <span style=\"color:blue\">Single Pixel Sanity Check</span>\n",
    "\n",
    "When dealing with a complicated system, it is often useful to perform a \"sanity check\" to make sure that a simpler subset of the system is working as expected, before adding more complexity. Let's make sure that the single pixel imager from Imaging Lab 2 works. \n",
    "\n",
    "**<span style=\"color:red\">Create $H_{Single}$ for images/masks with dimensions 32x32. How many rows should it have?</span>**\n",
    "\n",
    "*Note that $H_{Single}$ is the identity matrix (but it has different dimensions from $H$ in Lab 2)!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate `HSingle` to scan a 32x32 image. `HSingle` is the identity matrix.\n",
    "HSingle = # YOUR CODE HERE\n",
    "\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.imshow(HSingle, cmap = 'gray', interpolation = 'nearest')\n",
    "np.save('HSingle.npy', HSingle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check again that you have closed the Arduino IDE Serial Monitor. You will not be able to scan otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">You will then run the `capture_image.scan(...)` function from the following code block that projects mask patterns from $H_{Single}$ onto your image.</span>** \n",
    "\n",
    "`capture_image.scan(...)` iterates over the rows of the $H$ matrix you made. These rows are translated, one-by-one, into real masks projected onto the screen. Light sensor readings are taken for each mask.\n",
    "\n",
    "The whole scanning process should take roughly 4 minutes. \n",
    "\n",
    "*Note: On the topic of non-idealities, our scans take so long because:*\n",
    "* We average sensor readings to improve the signal-to-noise ratio. Therefore we need to read more times.\n",
    "* The projector takes a minimum of 16.6ms to display an image from the time it is received, since the display is driven at a rate of 60Hz.\n",
    "* Reading the sensor itself takes some time, about 100us per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not getting a good image?**\n",
    "\n",
    "Make sure you have the following:\n",
    "1. The projector turned on and oriented in the correct direction\n",
    "2. The projector input set to \"Digital\"\n",
    "3. Verified the mask is displaying from the projector\n",
    "    - You should see white squares scrolling across the projected screen\n",
    "4. Code successfully uploaded to the Arduino\n",
    "    - The Arduino IDE will notify you if the upload fails\n",
    "5. Nothing obstructing the ambient light sensor's view of the projected screen\n",
    "6. The taskbar disabled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "import capture_image\n",
    "\n",
    "HSingle = np.load('HSingle.npy')\n",
    "sr = capture_image.scan(HSingle, multi_pixel=False, width=32, height=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Recreate the image from the sensor readings obtained with `HSingle`. DO NOT move on until you have an acceptable recreation. Ask for help if you need to.</span>**\n",
    "\n",
    "*Note: Because we used 32x32 masks this time, the portion of the image we're able to \"see\" is smaller.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the image vector from `HSingle` and `sr`\n",
    "# Hint: Because `HSingle` is a special matrix, technically you do not need to perform any matrix operations\n",
    "iv = # YOUR CODE HERE\n",
    "\n",
    "img = np.reshape(iv, (32, 32))\n",
    "plt.imshow(img, cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id ='realImaging'><span style = \"color: blue\">Real Multipixel Imaging</span></a>\n",
    "\n",
    "In the previous section, we scanned our image one pixel at a time. Now we are going to use the two matrices you examined earlier to scan.\n",
    "\n",
    "Let's start with the random binary mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "import capture_image\n",
    "\n",
    "# Run scan\n",
    "randomH = generate_random_binary_mask(avg_1s_per_row = 300, plot=False)\n",
    "sr = capture_image.scan(randomH, multi_pixel=True, width=32, height=32, brightness=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Let's reconstruct your image. Based off of your simulation results, is this the reconstruction quality that you expected using `H`? Think about how noisy our actual imaging system is.</span>**\n",
    "\n",
    "Hint: This is NOT supposed to work well! Please don't spend too much time on this! Can you think of why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_multipixel(randomH, sr, width=32, height=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As expected, the randomly generated H matrix does not work well, if at all.** Please don't worry if your scan is not ideal!\n",
    "\n",
    "Next, let's try to image your index card using `hadamardH`. Imaging with `hadamardH` requires some additional pre-processing to stitch sensor readings (associated with the mask that we split) back together. This has been taken care of for you in the code below. \n",
    "\n",
    "**<span style=\"color:red\">Run the following code block. It will capture sensor readings using the Hadamard matrix `hadamardH`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "import capture_image\n",
    "\n",
    "# Run scan\n",
    "hadamardH = create_hadamard_matrix(shape=(32*32, 32*32), plot=False)\n",
    "sr = capture_image.scan(hadamardH, multi_pixel=True, width=32, height=32, brightness=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span >Don't worry if your sensor output \"looks\" incorrect. hadamardH is different from other matrices we've used before. We must reconstruct the image to check correctness. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_multipixel(hadamardH, sr, width=32, height=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your image is too bright (mostly white) or too dark (mostly black) and you do not get a decent quality reconstructed image, consider changing the `brightness` parameter in the `capture_image.scan(...)` function call above.\n",
    "- Image too bright $\\rightarrow$ decrease `brightness`\n",
    "- Image too dark $\\rightarrow$ increase `brightness`\n",
    "\n",
    "**Important note: `brightness` must remain within [0, 255] (0 to 255 inclusive)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Let's reconstruct your image. Based off of your simulation results, is this the reconstruction quality that you expected using `hadamardH`?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment on your reconstruction results when using `randomH` and `hadamardH`. In real imaging, which matrix did better? Did this match your expectations from simulation? Why? How did you expect multipixel imaging to compare to single pixel imaging from Imaging 2? What are some observed limitations of multipixel imaging?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='useCases'></a>\n",
    "# <span style=\"color:blue\">Task 4: Understanding Multipixel Use-Cases</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results you got in Task 3, you may be wondering why we'd ever use multipixel imaging at all. After all, we've significantly increased the complexity of our masks and reconstruction procedure only to produce images that don't seem to be any better (or are potentially even worse!) than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the advantages of multipixel imaging, let's return to our discussion of our mathematical model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{s} = H \\vec{i}_{est}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{s}$ can be interpreted as a vector of measurements: every time we project a mask onto our image and record the sensor data, it's stored as an element of $\\vec{s}$. As we've seen before, solving for $\\vec{i}$ yields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H^{-1}\\vec{s} = \\vec{i}_{est}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $H$ corresponds to a single-pixel setup, then 'unscrambling' (or 'inverting') $H$ will simply involve rearranging the order of elements in $\\vec{s}$ (or leaving it alone if $H$ is the identity matrix). In other words, if each row of $H$ has exactly one 1 with the remaining entries equal to 0, then the same will be true of $H^{-1}$. **Because of this, with single-pixel imaging, each value in $\\vec{i}_{est}$ depends on exactly one measurement!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this reasoning doesn't apply to multipixel imaging. If $H$ has multiple nonzero values in each row, then we expect $H^{-1}$ to behave similarly. **As such, with multipixel imaging, each value in $\\vec{i}_{est}$ can depend on several measurements.** This makes multipixel imaging more robust in certain circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For example, what happens if we're in a scenario where the power temporarily goes out during our scan?** In this case, we've essentially ruined a small set of our measurements. This is where we'll see a big difference between single and multipixel imaging: in single-pixel imaging, the pixels corresponding to those measurements will be irrecoverably lost, but we'll still get a decent image with multipixel imaging since each pixel's value is distributed over multiple measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this, we used the setup discussed in this lab to image this drawing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/camerashot.jpg\" align=\"center\" style=\"height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ruin some of our measurements, we simply opened the carboard box for ten seconds during our scans. Here's the result from the single-pixel scan:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/singleboxopen10s.png\" align=\"center\" style=\"height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you can make out most of the image, the pixels during which the box was open (the white strip) were clearly lost. Overall, this isn't a great picture. Let's see what happens when we do this with the Hadamard matrix instead:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/hadamardboxopen10s.png\" align=\"center\" style=\"height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We opened the box at the same time relative to the single-pixel scan, but we've retained at least some information on most of our pixels, producing a much better image. This is because the noise is distributed over the whole image rather than just over a certain number of pixels. **As is often the case in engineering, we've encountered a tradeoff: would we rather have some pixels recovered perfectly and others not so much, or should we compromise on overall image quality so that we at least get *some* information about *every* pixel?** This is the tradeoff between single and multipixel imaging!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">In your own words, when would you choose to use multipixel imaging instead of single-pixel imaging?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:red\"> Do not take apart your setup. Do not take any of it with you! </span>**\n",
    "\n",
    "**Please ensure you've placed the entire imaging setup box with the following items back on the station shelf:**\n",
    "\n",
    "1. Pico Projector\n",
    "2. Power Adapter\n",
    "3. Long micro USB cable\n",
    "4. Wooden Stand\n",
    "5. Arduino Leonardo\n",
    "6. Imaging circuit on breadboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feedback'></a>\n",
    "## Feedback\n",
    "If you have any feedback to give the teaching staff about the course (lab content, staff, etc), you can submit it through this Google form. Responses are **fully anonymous** and responses are actively monitored to improve the labs and course. Completing this form is **not required**.\n",
    "\n",
    "[Anyonymous feedback Google form](https://docs.google.com/forms/d/e/1FAIpQLScWVsuuiUC1NAqkhDiTtwmpt68Dy9N29rNiioluqo1CdngFNQ/viewform?usp=header)\n",
    "\n",
    "*If you have a personal matter to discuss or need a response to your feedback, please contact <a href=\"mailto:eecs16a.lab@berkeley.edu\">eecs16a.lab@berkeley.edu</a> and/or <a href=\"mailto:eecs16a@berkeley.edu\">eecs16a@berkeley.edu</a>*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='checkoff'></a>\n",
    "## Checkoff\n",
    "When you are ready to get checked off, fill out the checkoff google form. **[Checkoff Form](https://docs.google.com/forms/d/e/1FAIpQLSdIwjFcVYsHI8tfn3NtJD9MeJYvT0VmweR0smPgxHjYbNF22w/viewform?usp=header)**\n",
    "\n",
    "Your GSI or a Lab Assistant will join you when they are available and go through some checkoff questions with your group. They will go through the checkoff list in order. Please be patient!\n",
    "\n",
    "#### Post-checkoff Clean Up: (this applies to each week's lab)\n",
    "2. Throw away any trash at your station\n",
    "4. SIGN OUT of the computers - DO NOT SHUT DOWN\n",
    "5. Check that the projector is powered off and disconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
